{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (3.5.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (4.32.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (3.0.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (1.22.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import requests\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/Paper-With-Code/Siamese Neural Network\n"
     ]
    }
   ],
   "source": [
    "print(Path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = Path(\"/home/studio-lab-user/sagemaker-studiolab-notebooks\")  # Working directory.\n",
    "\n",
    "DATASET_DIR = ROOT_DIR / \"Data\"  # Directory to store dataset.\n",
    "DATA_DIR = DATASET_DIR / \"Omniglot\"  # Directory of dataset.\n",
    "\n",
    "DATASET_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)  # Create directory if it do not exist.\n",
    "\n",
    "image_dir = DATA_DIR / \"omniglot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/Data/Omniglot/omniglot\n"
     ]
    }
   ],
   "source": [
    "print(image_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exist!\n"
     ]
    }
   ],
   "source": [
    "if not image_dir.is_dir():\n",
    "    URL = \"https://www.dropbox.com/s/nfe0uj4eieivr2s/omniglot.zip?raw=1\"\n",
    "    file_name = \"omniglot.zip\"\n",
    "    file_path = DATA_DIR / file_name  # Download file path.\n",
    "\n",
    "    r = requests.get(URL, allow_redirects=True)\n",
    "    open(file_path, 'wb').write(r.content)\n",
    "\n",
    "    print('Dataset downloaded successfully!')\n",
    "\n",
    "\n",
    "    zip_file_path = file_path\n",
    "    extract_directory = DATA_DIR\n",
    "\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_directory)\n",
    "\n",
    "    Path.unlink(file_path)  # Remove zip file.\n",
    "\n",
    "    print('Dataset extracted successfully!')\n",
    "    \n",
    "else:\n",
    "    print('Dataset already exist!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_image_dir = image_dir / \"images_background\"\n",
    "evaluation_image_dir = image_dir / \"images_evaluation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/Data/Omniglot/omniglot/images_background\n"
     ]
    }
   ],
   "source": [
    "print(background_image_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(image_dir):\n",
    "    path_list = []  # Store the path of images.\n",
    "    class_list = []  # Store the class name.\n",
    "    \n",
    "    paths = Path(background_image_dir).glob('*')\n",
    "    \n",
    "    for path in paths:\n",
    "        # Because path is object not string.\n",
    "        path_str = str(path.name)  # Class name.\n",
    "        \n",
    "        sub_paths = Path(path).glob('*')\n",
    "    \n",
    "        for sub_path in sub_paths:\n",
    "            sub_path_str = str(sub_path.name)\n",
    "            class_list.append(path_str + '-' + sub_path_str)\n",
    "            \n",
    "            ssub_paths = Path(sub_path).glob('*')\n",
    "            \n",
    "            for ssub_path in ssub_paths:\n",
    "                ssub_path_str = str(ssub_path)  # path of image.\n",
    "                path_list.append(ssub_path_str)\n",
    "\n",
    "    return path_list, class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_list, train_class_list = create_dataset(background_image_dir)\n",
    "val_path_list, val_class_list = create_dataset(evaluation_image_dir)\n",
    "test_path_list, test_class_list = create_dataset(evaluation_image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images: 19285\n",
      "number of class: 964\n"
     ]
    }
   ],
   "source": [
    "print(\"number of images:\", len(train_path_list))\n",
    "print(\"number of class:\", len(train_class_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_class = {i:j for i, j in enumerate(train_class_list)}  # Add index to class.\n",
    "class_to_idx = {value:key for key,value in idx_to_class.items()}  # Convert class name to index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alphabet_of_the_Magi-character01\n",
      "0 Alphabet_of_the_Magi-character01\n",
      "1 Alphabet_of_the_Magi-character02\n",
      "2 Alphabet_of_the_Magi-character03\n",
      "3 Alphabet_of_the_Magi-character04\n",
      "4 Alphabet_of_the_Magi-character05\n",
      "temp_class has index: 0\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "temp_class = train_path_list[0].split('/')[-3] + \"-\" + train_path_list[0].split('/')[-2]  # Get class name from the path.\n",
    "print(temp_class)  \n",
    "\n",
    "for i in range(5):\n",
    "    print(i, idx_to_class[i])\n",
    "    \n",
    "print(\"temp_class has index:\", class_to_idx[temp_class])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Omniglot(Dataset):\n",
    "    def __init__(self, image_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image1_path = random.choice(self.image_paths)\n",
    "        # Get class name from the path.\n",
    "        image1_class_name = image1_path.split('/')[-3] + '-' + image1_path.split('/')[-2]\n",
    "        \n",
    "        # 50% of images to be in the same class.\n",
    "        from_same_class = random.randint(0, 1)  # 1 for same class.\n",
    "        \n",
    "        if from_same_class:\n",
    "            while True:\n",
    "                image2_path = random.choice(self.image_paths)\n",
    "                image2_class_name = image2_path.split('/')[-3] + '-' + image2_path.split('/')[-2]\n",
    "                if image1_class_name == image2_class_name:\n",
    "                    break\n",
    "        else:\n",
    "            while True:\n",
    "                image2_path = random.choice(self.image_paths)\n",
    "                image2_class_name = image2_path.split('/')[-3] + '-' + image2_path.split('/')[-2]\n",
    "                if image1_class_name != image2_class_name:\n",
    "                    break\n",
    "        \n",
    "        image1 = torchvision.io.read_image(image1_path)\n",
    "        image2 = torchvision.io.read_image(image2_path)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image1 = self.transform(image=image1)[\"image\"]\n",
    "            image2 = self.transform(image=image2)[\"image\"]\n",
    "        \n",
    "        label = from_same_class\n",
    "        \n",
    "        return image1, image2, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Omniglot(train_path_list)\n",
    "val_dataset = Omniglot(val_path_list)\n",
    "test_dataset = Omniglot(test_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 105, 105])\n",
      "torch.Size([1, 105, 105])\n",
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image1, image2, label in train_dataset:\n",
    "    print(image1.shape)\n",
    "    print(image2.shape)\n",
    "    print(label)\n",
    "    \n",
    "    f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    ax1.imshow(image1.permute(1, 2, 0))\n",
    "    ax2.imshow(image2.permute(1, 2, 0))\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=8)\n",
    "val_dataloader = DataLoader(val_dataset, shuffle=True, batch_size=8)\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=True, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 105, 105])\n",
      "torch.Size([8, 1, 105, 105])\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "for image1, image2, label in train_dataloader:\n",
    "    print(image1.shape)\n",
    "    print(image2.shape)\n",
    "    print(label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 10),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128, 128, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128, 256, 4),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(9216, 4096), \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.output = nn.Linear(4096, 1)\n",
    "        \n",
    "    def _forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self._forward(input1)\n",
    "        output2 = self._forward(input2)\n",
    "        distance = torch.abs(output1 - output2)\n",
    "        output = self.output(distance)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_network = SiameseNetwork()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    siamese_network.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 96, 96]           6,464\n",
      "              ReLU-2           [-1, 64, 96, 96]               0\n",
      "         MaxPool2d-3           [-1, 64, 48, 48]               0\n",
      "            Conv2d-4          [-1, 128, 42, 42]         401,536\n",
      "              ReLU-5          [-1, 128, 42, 42]               0\n",
      "         MaxPool2d-6          [-1, 128, 21, 21]               0\n",
      "            Conv2d-7          [-1, 128, 18, 18]         262,272\n",
      "              ReLU-8          [-1, 128, 18, 18]               0\n",
      "         MaxPool2d-9            [-1, 128, 9, 9]               0\n",
      "           Conv2d-10            [-1, 256, 6, 6]         524,544\n",
      "             ReLU-11            [-1, 256, 6, 6]               0\n",
      "           Linear-12                 [-1, 4096]      37,752,832\n",
      "          Sigmoid-13                 [-1, 4096]               0\n",
      "           Conv2d-14           [-1, 64, 96, 96]           6,464\n",
      "             ReLU-15           [-1, 64, 96, 96]               0\n",
      "        MaxPool2d-16           [-1, 64, 48, 48]               0\n",
      "           Conv2d-17          [-1, 128, 42, 42]         401,536\n",
      "             ReLU-18          [-1, 128, 42, 42]               0\n",
      "        MaxPool2d-19          [-1, 128, 21, 21]               0\n",
      "           Conv2d-20          [-1, 128, 18, 18]         262,272\n",
      "             ReLU-21          [-1, 128, 18, 18]               0\n",
      "        MaxPool2d-22            [-1, 128, 9, 9]               0\n",
      "           Conv2d-23            [-1, 256, 6, 6]         524,544\n",
      "             ReLU-24            [-1, 256, 6, 6]               0\n",
      "           Linear-25                 [-1, 4096]      37,752,832\n",
      "          Sigmoid-26                 [-1, 4096]               0\n",
      "           Linear-27                    [-1, 1]           4,097\n",
      "================================================================\n",
      "Total params: 77,899,393\n",
      "Trainable params: 77,899,393\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 463.68\n",
      "Forward/backward pass size (MB): 29.83\n",
      "Params size (MB): 297.16\n",
      "Estimated Total Size (MB): 790.67\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(siamese_network, input_size=[(1, 105, 105), (1, 105, 105)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.BCEWithLogitsLoss(size_average=True)\n",
    "optimizer = optim.Adam(siamese_network.parameters(), lr = 0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([8, 1, 105, 105])\n",
      "torch.Size([8, 1, 105, 105])\n",
      "torch.Size([8])\n",
      "torch.uint8\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "for i, (image0, image1, label) in enumerate(train_dataloader):\n",
    "    print(i)\n",
    "    print(image0.shape)\n",
    "    print(image1.shape)\n",
    "    print(label.shape)\n",
    "    \n",
    "    print(image0.dtype)\n",
    "    print(label.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = []\n",
    "loss_history = [] \n",
    "iteration_number= 0\n",
    "loss_val = 0\n",
    "\n",
    "for epoch in range(100):\n",
    "    for i, (image0, image1, label) in enumerate(train_dataloader):\n",
    "        \n",
    "        # image0, image1, label = image0.cuda(), image1.cuda(), label.cuda()\n",
    "        image0, image1 = image0.float(), image1.float()\n",
    "        label = label.reshape(-1, 1).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = siamese_network(image0, image1)\n",
    "        \n",
    "        loss = loss_fn(output, label)\n",
    "        \n",
    "        loss_val += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    \n",
    "    print(f\"Epoch number {epoch}\\n Current loss {loss.item()}\\n\")\n",
    "    iteration_number += 10\n",
    "\n",
    "    counter.append(iteration_number)\n",
    "    loss_history.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
